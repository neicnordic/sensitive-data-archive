package sda

import (
	"bytes"
	"context"
	"crypto/tls"
	"crypto/x509"
	"errors"
	"fmt"
	"io"
	"math"
	"net/http"
	"os"
	"regexp"
	"strconv"
	"strings"
	"time"

	"github.com/gin-gonic/gin"
	"github.com/neicnordic/crypt4gh/streaming"
	"github.com/neicnordic/sda-download/api/middleware"
	"github.com/neicnordic/sda-download/internal/config"
	"github.com/neicnordic/sda-download/internal/database"
	"github.com/neicnordic/sda-download/internal/reencrypt"
	"github.com/neicnordic/sda-download/internal/storage"
	log "github.com/sirupsen/logrus"
	"google.golang.org/grpc"
	"google.golang.org/grpc/credentials"
	"google.golang.org/grpc/credentials/insecure"
)

var Backend storage.Backend

func sanitizeString(str string) string {
	var pattern = regexp.MustCompile(`(https?://[^\s/$.?#].[^\s]+|[A-Za-z0-9-_:.]+)`)

	return pattern.ReplaceAllString(str, "[identifier]: $1")
}

func reencryptHeader(oldHeader []byte, reencKey string) ([]byte, error) {
	var opts []grpc.DialOption
	switch {
	case config.Config.Reencrypt.ClientKey != "" && config.Config.Reencrypt.ClientCert != "":
		rootCAs, err := x509.SystemCertPool()
		if err != nil {
			log.Errorf("failed to read system CAs: %v, using an empty pool as base", err)
			rootCAs = x509.NewCertPool()
		}
		if config.Config.Reencrypt.CACert != "" {
			cacertByte, err := os.ReadFile(config.Config.Reencrypt.CACert)
			if err != nil {
				log.Errorf("Failed to read CA certificate file, reason: %s", err)

				return nil, err
			}
			ok := rootCAs.AppendCertsFromPEM(cacertByte)
			if !ok {
				log.Errorf("Failed to append CA certificate to rootCAs")

				return nil, errors.New("failed to append CA certificate to cert pool")
			}
		}

		certs, err := tls.LoadX509KeyPair(config.Config.Reencrypt.ClientCert, config.Config.Reencrypt.ClientKey)
		if err != nil {
			log.Errorf("Failed to load client key pair for reencrypt, reason: %s", err)

			return nil, err
		}
		clientCreds := credentials.NewTLS(
			&tls.Config{
				Certificates: []tls.Certificate{certs},
				MinVersion:   tls.VersionTLS13,
				RootCAs:      rootCAs,
			},
		)

		opts = append(opts, grpc.WithTransportCredentials(clientCreds))
	default:
		opts = append(opts, grpc.WithTransportCredentials(insecure.NewCredentials()))
	}

	address := fmt.Sprintf("%s:%d", config.Config.Reencrypt.Host, config.Config.Reencrypt.Port)
	log.Debugf("Address of the reencrypt service: %s", address)

	conn, err := grpc.NewClient(address, opts...)
	if err != nil {
		log.Errorf("Failed to connect to the reencrypt service, reason: %s", err)

		return nil, err
	}
	defer conn.Close()

	timeoutDuration := time.Duration(config.Config.Reencrypt.Timeout) * time.Second
	ctx, cancel := context.WithTimeout(context.Background(), timeoutDuration)
	defer cancel()

	c := reencrypt.NewReencryptClient(conn)
	log.Debugf("Client created, c = %v", c)
	res, err := c.ReencryptHeader(ctx, &reencrypt.ReencryptRequest{Oldheader: oldHeader, Publickey: reencKey})
	if err != nil {
		log.Errorf("Failed response from the reencrypt service, reason: %s", err)

		return nil, err
	}

	return res.Header, nil
}

// Datasets serves a list of permitted datasets
func Datasets(c *gin.Context) {
	log.Debugf("request permitted datasets")

	// Retrieve dataset list from request context
	// generated by the authentication middleware
	cache := middleware.GetCacheFromContext(c)

	// Return response
	c.JSON(http.StatusOK, cache.Datasets)
}

// find looks for a dataset name in a list of datasets
func find(datasetID string, datasets []string) bool {
	found := false
	for _, dataset := range datasets {
		if datasetID == dataset {
			found = true

			break
		}
	}

	return found
}

// getFiles returns files belonging to a dataset
var getFiles = func(datasetID string, ctx *gin.Context) ([]*database.FileInfo, int, error) {

	// Retrieve dataset list from request context
	// generated by the authentication middleware
	cache := middleware.GetCacheFromContext(ctx)

	log.Debugf("request to process files for dataset %s", sanitizeString(datasetID))

	if find(datasetID, cache.Datasets) {
		// Get file metadata
		files, err := database.GetFiles(datasetID)
		if err != nil {
			// something went wrong with querying or parsing rows
			log.Errorf("database query failed for dataset %s, reason %s", sanitizeString(datasetID), err)

			return nil, 500, errors.New("database error")
		}

		return files, 200, nil
	}

	return nil, 404, errors.New("dataset not found")
}

// Files serves a list of files belonging to a dataset
func Files(c *gin.Context) {

	// get dataset parameter
	dataset := c.Param("dataset")

	if !strings.HasSuffix(dataset, "/files") {
		c.String(http.StatusNotFound, "API path not found, maybe /files is missing")

		return
	}

	// remove / prefix and /files suffix
	dataset = strings.TrimPrefix(dataset, "/")
	dataset = strings.TrimSuffix(dataset, "/files")

	// Get optional dataset scheme
	// A scheme can be delivered separately in a query parameter
	// as schemes may sometimes be problematic when they travel
	// in the path. A client can conveniently split the scheme with "://"
	// which results in 1 item if there is no scheme (e.g. EGAD) or 2 items
	// if there was a scheme (e.g. DOI)
	scheme := c.Query("scheme")
	schemeLogs := strings.ReplaceAll(scheme, "\n", "")
	schemeLogs = strings.ReplaceAll(schemeLogs, "\r", "")

	datasetLogs := strings.ReplaceAll(dataset, "\n", "")
	datasetLogs = strings.ReplaceAll(datasetLogs, "\r", "")
	if scheme != "" {
		log.Debugf("adding scheme=%s to dataset=%s", schemeLogs, datasetLogs)
		dataset = fmt.Sprintf("%s://%s", scheme, dataset)
		log.Debugf("new dataset=%s", datasetLogs)
	}

	// Get dataset files
	files, code, err := getFiles(dataset, c)
	if err != nil {
		c.String(code, err.Error())

		return
	}

	// Return response
	c.JSON(http.StatusOK, files)
}

// Download serves file contents as bytes
func Download(c *gin.Context) {
	// This conditional should always be satisfied for /s3 since the c.Param is set to  encrypted
	// when PublicKeyB64 is not set or empty, but this is not the case for calls to /files endpoint.
	// This is because the /files endpoint does not support encrypted files atm.
	// So we need this check.
	// Checking the type instead of the field S3 is better because it also provides a sanity check for the /s3 case.

	if c.Param("type") != "encrypted" && config.Config.C4GH.PublicKeyB64 == "" {
		c.String(http.StatusBadRequest, "downloading unencrypted data is not supported")

		return
	}

	if c.Param("type") != "encrypted" && c.GetHeader("Client-Public-Key") != "" {
		c.String(http.StatusBadRequest, "downloading encrypted data is not supported")

		return
	}

	// Get file ID from path
	fileID := c.Param("fileid")

	// Check user has permissions for this file (as part of a dataset)
	dataset, err := database.CheckFilePermission(fileID)
	if err != nil {
		c.String(http.StatusNotFound, "file not found")

		return
	}

	// Get datasets from request context, parsed previously by token middleware
	cache := middleware.GetCacheFromContext(c)

	// Verify user has permission to datafile
	permission := false
	for d := range cache.Datasets {
		if cache.Datasets[d] == dataset {
			permission = true

			break
		}
	}
	if !permission {
		log.Debugf("user requested to view file, but does not have permissions for dataset %s", dataset)
		c.String(http.StatusUnauthorized, "unauthorised")

		return
	}

	// Get file header
	fileDetails, err := database.GetFile(fileID)
	if err != nil {
		c.String(http.StatusInternalServerError, "database error")

		return
	}

	// Get query params
	qStart := c.DefaultQuery("startCoordinate", "0")
	qEnd := c.DefaultQuery("endCoordinate", "0")

	// Parse and verify coordinates are valid
	start, err := strconv.ParseInt(qStart, 10, 0)

	if err != nil {
		log.Errorf("failed to convert start coordinate %d to integer, %s", start, err)
		c.String(http.StatusBadRequest, "startCoordinate must be an integer")

		return
	}
	end, err := strconv.ParseInt(qEnd, 10, 0)
	if err != nil {
		log.Errorf("failed to convert end coordinate %d to integer, %s", end, err)
		c.String(http.StatusBadRequest, "endCoordinate must be an integer")

		return
	}
	if end < start {
		log.Errorf("endCoordinate=%d must be greater than startCoordinate=%d", end, start)
		c.String(http.StatusBadRequest, "endCoordinate must be greater than startCoordinate")

		return
	}

	wholeFile := true
	if start != 0 || end != 0 {
		wholeFile = false
	}

	start, end, err = calculateCoords(start, end, c.GetHeader("Range"), fileDetails, c.Param("type"))
	if err != nil {
		log.Errorf("Byte range coordinates invalid! %v", err)

		return
	}
	if c.Param("type") != "encrypted" {
		// set the content-length for unencrypted files
		if start == 0 && end == 0 {
			c.Header("Content-Length", fmt.Sprint(fileDetails.DecryptedSize))
		} else {
			// Calculate how much we should read (if given)
			togo := end - start
			c.Header("Content-Length", fmt.Sprint(togo))
		}
	}

	// Get archive file handle
	var file io.Reader

	if wholeFile {
		file, err = Backend.NewFileReader(fileDetails.ArchivePath)
	} else {
		file, err = Backend.NewFileReadSeeker(fileDetails.ArchivePath)
	}

	if err != nil {
		log.Errorf("could not find archive file %s, %s", fileDetails.ArchivePath, err)
		c.String(http.StatusInternalServerError, "archive error")

		return
	}

	c.Header("Content-Type", "application/octet-stream")
	if c.GetBool("S3") {
		lastModified, err := time.Parse(time.RFC3339, fileDetails.LastModified)
		if err != nil {
			log.Errorf("failed to parse last modified time: %v", err)
			c.AbortWithStatus(http.StatusInternalServerError)

			return
		}

		c.Header("Content-Disposition", fmt.Sprintf("filename: %v", fileID))
		c.Header("ETag", fileDetails.DecryptedChecksum)
		c.Header("Last-Modified", lastModified.Format(http.TimeFormat))

		// set the user and server public keys that is send from htsget
		log.Debugf("Got to setting the headers: %s", c.GetHeader("client-public-key"))
		c.Header("Client-Public-Key", c.GetHeader("Client-Public-Key"))
	}

	if c.Request.Method == http.MethodHead {

		// Create headers for htsget, containing size of the crypt4gh header
		reencKey := c.GetHeader("Client-Public-Key")
		headerSize := bytes.NewReader(fileDetails.Header).Size()
		// Size of the header in the archive
		c.Header("Server-Additional-Bytes", fmt.Sprint(headerSize))
		if reencKey != "" {
			newHeader, _ := reencryptHeader(fileDetails.Header, reencKey)
			headerSize = bytes.NewReader(newHeader).Size()
			// Size of the header if the file is re-encrypted before downloading
			c.Header("Client-Additional-Bytes", fmt.Sprint(headerSize))
		}
		if c.Param("type") == "encrypted" {
			// Update the content length to match the encrypted file size
			c.Header("Content-Length", fmt.Sprint(int(headerSize)+fileDetails.ArchiveSize))
		}

		return
	}

	// Prepare the file for streaming, encrypted or decrypted

	var fileStream io.Reader

	switch c.Param("type") {
	case "encrypted":
		// The key provided in the header should be base64 encoded
		reencKey := c.GetHeader("Client-Public-Key")
		if reencKey == "" {
			c.String(http.StatusBadRequest, "c4gh public key is missing from the header")

			return
		}

		log.Debugf("Public key from the request header = %v", reencKey)
		newHeader, err := reencryptHeader(fileDetails.Header, reencKey)
		if err != nil {
			log.Errorf("Failed to reencrypt the file header, reason: %v", err)
			c.String(http.StatusInternalServerError, "file re-encryption error")

			return
		}

		newHr := bytes.NewReader(newHeader)

		if wholeFile {
			fileStream = io.MultiReader(newHr, file)
		} else {
			seeker, _ := file.(io.ReadSeeker)
			seekStream, err := storage.SeekableMultiReader(newHr, seeker)
			if err != nil {
				log.Errorf("Failed to construct SeekableMultiReader, reason: %v", err)
				c.String(http.StatusInternalServerError, "file decoding error")

				return
			}
			start, end, err = adjustSeekPos(seekStream, start, end)
			if err != nil {
				log.Errorf("Could not seek stream: %v", err)
				c.String(http.StatusInternalServerError, "file decoding error")

				return
			}
			fileStream = seekStream
		}
	default:
		// Reencrypt header for use with the loaded internal key
		newHeader, err := reencryptHeader(fileDetails.Header, config.Config.C4GH.PublicKeyB64)
		if err != nil {
			log.Errorf("Failed to reencrypt the file header, reason: %v", err)
			c.String(http.StatusInternalServerError, "file re-encryption error")

			return
		}

		newHr := bytes.NewReader(newHeader)

		if wholeFile {
			fileStream = io.MultiReader(newHr, file)
		} else {
			seeker, _ := file.(io.ReadSeeker)
			fileStream, err = storage.SeekableMultiReader(newHr, seeker)
			if err != nil {
				log.Errorf("Failed to construct SeekableMultiReader, reason: %v", err)
				c.String(http.StatusInternalServerError, "file decoding error")

				return
			}
		}

		c4ghfileStream, err := streaming.NewCrypt4GHReader(fileStream, config.Config.C4GH.PrivateKey, nil)
		defer c4ghfileStream.Close()
		if err != nil {
			log.Errorf("could not prepare file for streaming, %s", err)
			c.String(http.StatusInternalServerError, "file stream error")

			return
		}
		start, end, err = adjustSeekPos(c4ghfileStream, start, end)
		if err != nil {
			log.Errorf("Could not seek stream: %v", err)
			c.String(http.StatusInternalServerError, "file decoding error")

			return
		}
		fileStream = c4ghfileStream
	}

	err = sendStream(fileStream, c.Writer, start, end)
	if err != nil {
		log.Errorf("error occurred while sending stream: %v", err)
		c.String(http.StatusInternalServerError, "an error occurred")

		return
	}
}

var adjustSeekPos = func(fileStream io.ReadSeeker, start, end int64) (int64, int64, error) {
	if start != 0 {

		// We don't want to read from start, skip ahead to where we should be
		_, err := fileStream.Seek(start, 0)
		if err != nil {

			return 0, 0, fmt.Errorf("error occurred while finding sending start: %v", err)
		}
		// adjust end to reflect that the file start has been moved
		end -= start
		start = 0

	}

	return start, end, nil
}

// used from: https://github.com/neicnordic/crypt4gh/blob/master/examples/reader/main.go#L48C1-L113C1
var sendStream = func(reader io.Reader, writer http.ResponseWriter, start, end int64) error {

	// Calculate how much we should read (if given)
	togo := end - start

	buf := make([]byte, 4096)

	// Loop until we've read what we should (if no/faulty end given, that's EOF)
	for end == 0 || togo > 0 {
		rbuf := buf

		if end != 0 && togo < 4096 {
			// If we don't want to read as much as 4096 bytes
			rbuf = buf[:togo]
		}
		r, err := reader.Read(rbuf)
		togo -= int64(r)

		// Nothing more to read?
		if err == io.EOF && r == 0 {
			// Fall out without error if we had EOF (if we got any data, do one
			// more lap in the loop)
			return nil
		}

		if err != nil && err != io.EOF {
			// An error we want to signal?
			return err
		}

		wbuf := rbuf[:r]
		for len(wbuf) > 0 {
			// Loop until we've written all that we could read,
			// fall out on error
			w, err := writer.Write(wbuf)

			if err != nil {
				return err
			}
			wbuf = wbuf[w:]
		}
	}

	return nil
}

// Calculates the start and end coordinats to use. If a range is set in HTTP headers,
// it will be used as is. If not, the functions parameters will be used.
// If in encrypted mode, the parameters will be adjusted to match the data block boundaries.
var calculateCoords = func(start, end int64, htsget_range string, fileDetails *database.FileDownload, encryptedType string) (int64, int64, error) {
	log.Warnf("calculate")
	if htsget_range != "" {
		startEnd := strings.Split(strings.TrimPrefix(htsget_range, "bytes="), "-")
		if len(startEnd) > 1 {
			a, err := strconv.ParseInt(startEnd[0], 10, 64)
			if err != nil {
				return 0, 0, err
			}
			b, err := strconv.ParseInt(startEnd[1], 10, 64)
			if err != nil {
				return 0, 0, err
			}
			if a > b {
				return 0, 0, fmt.Errorf("endCoordinate must be greater than startCoordinate")
			}

			// Byte ranges are inclusive; +1 so that the last byte is included

			return a, b + 1, nil
		}
	}

	// For unencrypted files, return the coordinates as is
	if encryptedType != "encrypted" {
		return start, end, nil
	}

	// Adapt end coordinate to follow the crypt4gh block boundaries
	headlength := bytes.NewReader(fileDetails.Header)
	bodyEnd := int64(fileDetails.ArchiveSize)
	if end > 0 {
		var packageSize float64 = 65564 // 64KiB+28, 28 is for chacha20_ietf_poly1305
		togo := end - start
		bodysize := math.Max(float64(togo-headlength.Size()), 0)
		endCoord := packageSize * math.Ceil(bodysize/packageSize)
		bodyEnd = int64(math.Min(float64(bodyEnd), endCoord))
	}

	return start, headlength.Size() + bodyEnd, nil

}
